@author: Shreya Agrawal
@date: 31st Jan 2019


Installing Pyspark on Windows:

1. 	install spark from https://spark.apache.org/downloads.html

2.	create folder C:\Users\agrashre\spark and unzip here. 
	Folder structure after unzipping C:\Users\agrashre\spark\bin, etc

3. 	install winutils in C:\Users\agrashre\winutils

4. 	install java jdk in C:\Users\agrashre\java

5. 	create folder C:\Users\agrashre\tmp\hive

6. 	Put DataBricks jar in spark\jar (if you want to use csv/avro)
	To use avro format, you will need version spark-avro_2.11-4.0.0 or greater.
	https://mvnrepository.com/artifact/com.databricks/spark-avro_2.11/4.0.0
	

7. 	Set the following path variables: 
	(Change this a/c to your installation locations.)
	
	SPARK_HOME=C:\Users\agrashre\spark

    JAVA_HOME=C:\Users\agrashre\java

    HADOOP_HOME=C:\Users\agrashre\winutils

	
	
Some useful pointers:

1.	After this, spark is installed on your local computer. It is possible that you may not have installed pyspark module explicitly.
	However when you spark-submit your code, it will be autodetected.

2. 	Ensure that there are no spaces in path variables. Spark has some issues if that happens.

3. 	If you are unable to change your system variables or do not want to mess with them, then you can create a .bat file as I have 
	and run it before every spark-submit execution cycle.

	

That's all for now. Happy coding!
